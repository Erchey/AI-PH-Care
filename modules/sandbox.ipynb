{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d15800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RAG System for Medical Knowledge Retrieval\n",
    "Uses vector embeddings to retrieve relevant medical information from documents\n",
    "\"\"\"\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    WebBaseLoader\n",
    ")\n",
    "from langchain.schema import Document\n",
    "from typing import List, Dict\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class MedicalRAGSystem:\n",
    "    \"\"\"\n",
    "    RAG system for retrieving medical knowledge from documents\n",
    "    Supports PDFs, web links, text files, and markdown\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, persist_directory=\"./vector_store\"):\n",
    "        self.llm = llm\n",
    "        self.persist_directory = persist_directory\n",
    "        \n",
    "        # Initialize embeddings (can work offline)\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            model_kwargs={'device': 'cpu'}\n",
    "        )\n",
    "        \n",
    "        # Initialize or load vector store\n",
    "        self.vector_store = self._initialize_vector_store()\n",
    "        \n",
    "        # Text splitter for chunking documents\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "    \n",
    "    def _initialize_vector_store(self):\n",
    "        \"\"\"Initialize or load existing vector store\"\"\"\n",
    "        \n",
    "        if os.path.exists(self.persist_directory):\n",
    "            print(\"Loading existing vector store...\")\n",
    "            return Chroma(\n",
    "                persist_directory=self.persist_directory,\n",
    "                embedding_function=self.embeddings\n",
    "            )\n",
    "        else:\n",
    "            print(\"Creating new vector store...\")\n",
    "            return Chroma(\n",
    "                persist_directory=self.persist_directory,\n",
    "                embedding_function=self.embeddings\n",
    "            )\n",
    "    \n",
    "    def ingest_document(self, file_path: str, metadata: Dict = None):\n",
    "        \"\"\"\n",
    "        Ingest a document into the RAG system\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to document or URL\n",
    "            metadata: Additional metadata (source, category, etc.)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Determine loader based on file type\n",
    "        if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "            loader = WebBaseLoader(file_path)\n",
    "            doc_type = \"web\"\n",
    "        elif file_path.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            doc_type = \"pdf\"\n",
    "        elif file_path.endswith(\".md\"):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "            doc_type = \"markdown\"\n",
    "        else:\n",
    "            loader = TextLoader(file_path)\n",
    "            doc_type = \"text\"\n",
    "        \n",
    "        # Load and split documents\n",
    "        documents = loader.load()\n",
    "        splits = self.text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Add metadata\n",
    "        for doc in splits:\n",
    "            doc.metadata.update({\n",
    "                \"source\": file_path,\n",
    "                \"doc_type\": doc_type,\n",
    "                **(metadata or {})\n",
    "            })\n",
    "        \n",
    "        # Add to vector store\n",
    "        self.vector_store.add_documents(splits)\n",
    "        self.vector_store.persist()\n",
    "        \n",
    "        print(f\"✓ Ingested {len(splits)} chunks from {file_path}\")\n",
    "        \n",
    "        return len(splits)\n",
    "    \n",
    "\n",
    "    def ingest_folder(self, folder_path: str = \"../medical_docs\"):\n",
    "        \"\"\"\n",
    "        Ingest and vectorize all documents inside a folder.\n",
    "        Automatically handles PDF, text, markdown, and web link files.\n",
    "\n",
    "        Args:\n",
    "            folder_path: Directory containing documents.\n",
    "        \"\"\"\n",
    "        import glob\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"⚠️ Folder not found: {folder_path}\")\n",
    "            return 0\n",
    "\n",
    "        supported_ext = (\".pdf\", \".txt\", \".md\")\n",
    "        files = []\n",
    "        for ext in supported_ext:\n",
    "            files.extend(glob.glob(os.path.join(folder_path, f\"*{ext}\")))\n",
    "\n",
    "        if not files:\n",
    "            print(f\"⚠️ No supported documents found in {folder_path}\")\n",
    "            return 0\n",
    "\n",
    "        total_chunks = 0\n",
    "        for file_path in files:\n",
    "            try:\n",
    "                chunks = self.ingest_document(file_path)\n",
    "                total_chunks += chunks\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error ingesting {file_path}: {e}\")\n",
    "\n",
    "        print(f\"\\n✅ Finished ingesting {len(files)} documents ({total_chunks} chunks total)\")\n",
    "        return total_chunks\n",
    "\n",
    "\n",
    "\n",
    "    def ingest_bulk(self, sources: List[Dict]):\n",
    "        \"\"\"\n",
    "        Ingest multiple documents at once\n",
    "        \n",
    "        Args:\n",
    "            sources: List of dicts with 'path' and 'metadata'\n",
    "        \"\"\"\n",
    "        \n",
    "        total_chunks = 0\n",
    "        for source in sources:\n",
    "            try:\n",
    "                chunks = self.ingest_document(\n",
    "                    source['path'],\n",
    "                    source.get('metadata', {})\n",
    "                )\n",
    "                total_chunks += chunks\n",
    "            except Exception as e:\n",
    "                print(f\"Error ingesting {source['path']}: {e}\")\n",
    "        \n",
    "        print(f\"\\n✓ Total: Ingested {total_chunks} chunks from {len(sources)} sources\")\n",
    "        \n",
    "        return total_chunks\n",
    "    \n",
    "    def retrieve(self, query: str, k: int = 4, filter_metadata: Dict = None):\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of documents to retrieve\n",
    "            filter_metadata: Filter by metadata (e.g., category, source)\n",
    "        \n",
    "        Returns:\n",
    "            List of relevant documents with content and metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        # Perform similarity search\n",
    "        if filter_metadata:\n",
    "            docs = self.vector_store.similarity_search(\n",
    "                query,\n",
    "                k=k,\n",
    "                filter=filter_metadata\n",
    "            )\n",
    "        else:\n",
    "            docs = self.vector_store.similarity_search(query, k=k)\n",
    "        \n",
    "        # Format results\n",
    "        results = []\n",
    "        for doc in docs:\n",
    "            results.append({\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"source\": doc.metadata.get(\"source\", \"Unknown\")\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def retrieve_with_scores(self, query: str, k: int = 4):\n",
    "        \"\"\"Retrieve documents with relevance scores\"\"\"\n",
    "        \n",
    "        docs_with_scores = self.vector_store.similarity_search_with_score(query, k=k)\n",
    "        \n",
    "        results = []\n",
    "        for doc, score in docs_with_scores:\n",
    "            results.append({\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"relevance_score\": score,\n",
    "                \"source\": doc.metadata.get(\"source\", \"Unknown\")\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def answer_with_sources(self, query: str, k: int = 4):\n",
    "        \"\"\"\n",
    "        Answer a query using RAG with source citations\n",
    "        \n",
    "        Args:\n",
    "            query: User's question\n",
    "            k: Number of source documents to retrieve\n",
    "        \n",
    "        Returns:\n",
    "            AI-generated answer with source citations\n",
    "        \"\"\"\n",
    "        \n",
    "        # Retrieve relevant documents\n",
    "        retrieved_docs = self.retrieve(query, k=k)\n",
    "        \n",
    "        if not retrieved_docs:\n",
    "            return {\n",
    "                \"answer\": \"I don't have enough information in my knowledge base to answer this query confidently. Please consult medical guidelines or a senior healthcare professional.\",\n",
    "                \"sources\": []\n",
    "            }\n",
    "        \n",
    "        # Build context from retrieved documents\n",
    "        context = \"\\n\\n\".join([\n",
    "            f\"Source {i+1}: {doc['content']}\"\n",
    "            for i, doc in enumerate(retrieved_docs)\n",
    "        ])\n",
    "        \n",
    "        # Generate answer using LLM\n",
    "        prompt = f\"\"\"Based on the following medical knowledge sources, answer the healthcare question accurately and concisely.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Medical Knowledge:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- Provide a clear, evidence-based answer\n",
    "- Cite which sources support your answer (e.g., \"According to Source 1...\")\n",
    "- If information is insufficient, state that clearly\n",
    "- For clinical decisions, recommend consulting a healthcare professional\n",
    "- Use simple language appropriate for PHC workers\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        response = self.llm.invoke(prompt)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response.content,\n",
    "            \"sources\": retrieved_docs,\n",
    "            \"query\": query\n",
    "        }\n",
    "    \n",
    "    def semantic_search(self, query: str, category: str = None, k: int = 5):\n",
    "        \"\"\"\n",
    "        Perform semantic search with optional category filtering\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            category: Filter by category (protocols, drugs, diagnosis, etc.)\n",
    "            k: Number of results\n",
    "        \"\"\"\n",
    "        \n",
    "        filter_dict = {\"category\": category} if category else None\n",
    "        \n",
    "        results = self.retrieve(query, k=k, filter_metadata=filter_dict)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_emergency_protocol(self, condition: str):\n",
    "        \"\"\"Retrieve emergency protocol using RAG\"\"\"\n",
    "        \n",
    "        query = f\"emergency protocol for {condition} immediate treatment steps\"\n",
    "        \n",
    "        return self.answer_with_sources(query, k=3)\n",
    "    \n",
    "    def get_drug_information(self, drug_name: str):\n",
    "        \"\"\"Retrieve drug information using RAG\"\"\"\n",
    "        \n",
    "        query = f\"{drug_name} dosage contraindications side effects interactions\"\n",
    "        \n",
    "        return self.answer_with_sources(query, k=3)\n",
    "    \n",
    "    def get_diagnostic_guidance(self, symptoms: str):\n",
    "        \"\"\"Get diagnostic guidance for symptoms\"\"\"\n",
    "        \n",
    "        query = f\"diagnosis differential diagnosis for patient with {symptoms}\"\n",
    "        \n",
    "        return self.answer_with_sources(query, k=4)\n",
    "    \n",
    "    def clear_store(self):\n",
    "        \"\"\"Clear the vector store (use with caution)\"\"\"\n",
    "        \n",
    "        import shutil\n",
    "        if os.path.exists(self.persist_directory):\n",
    "            shutil.rmtree(self.persist_directory)\n",
    "            print(\"✓ Vector store cleared\")\n",
    "        \n",
    "        self.vector_store = self._initialize_vector_store()\n",
    "\n",
    "\n",
    "def setup_initial_knowledge_base(rag_system: MedicalRAGSystem):\n",
    "    \"\"\"\n",
    "    Setup initial knowledge base with medical resources\n",
    "    This is where you'd add your medical documents and URLs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Example sources - replace with actual medical guidelines\n",
    "    sources = [\n",
    "        {\n",
    "            \"path\": \"https://www.who.int/publications/guidelines\",\n",
    "            \"metadata\": {\n",
    "                \"category\": \"guidelines\",\n",
    "                \"source_org\": \"WHO\",\n",
    "                \"language\": \"English\"\n",
    "            }\n",
    "        },\n",
    "        # Add your medical PDFs\n",
    "        {\n",
    "            \"path\": \"./medical_docs/emergency_protocols.pdf\",\n",
    "            \"metadata\": {\n",
    "                \"category\": \"emergency\",\n",
    "                \"doc_type\": \"protocol\"\n",
    "            }\n",
    "        },\n",
    "        # Add drug formularies\n",
    "        {\n",
    "            \"path\": \"./medical_docs/essential_medicines.pdf\",\n",
    "            \"metadata\": {\n",
    "                \"category\": \"drugs\",\n",
    "                \"doc_type\": \"formulary\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"Setting up medical knowledge base...\")\n",
    "    print(\"Note: Add your actual medical documents and URLs above\")\n",
    "    \n",
    "    # Only ingest if files exist\n",
    "    for source in sources:\n",
    "        path = source['path']\n",
    "        if path.startswith(\"http\") or os.path.exists(path):\n",
    "            try:\n",
    "                rag_system.ingest_document(path, source.get('metadata'))\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not ingest {path}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337854fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELITEBOOK\\AppData\\Local\\Temp\\ipykernel_28132\\3165073762.py:100: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  self.vector_store.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ingested 93 chunks from ../medical_docs\\177_1584210847.pdf\n",
      "✓ Ingested 280 chunks from ../medical_docs\\BHCPF-2020-Guidelines.pdf\n",
      "✓ Ingested 224 chunks from ../medical_docs\\DSD-guidelines-Nigeria.pdf\n",
      "✓ Ingested 55 chunks from ../medical_docs\\GUIDELINES-FOR-HOSPITAL-REGISTRATION_compressed.pdf\n",
      "✓ Ingested 306 chunks from ../medical_docs\\Guidelines_for_Pain_Mgt_-_Copy_Presented_to_NCH_-20_June_2018_-_FINAL_COPY_-_NEW.pdf\n",
      "✓ Ingested 22 chunks from ../medical_docs\\INFECTION-PREVENTION-AND-CONTROL-IPC-STANDARD-OPERATING-PROCEDURE-SOP-.pdf\n",
      "✓ Ingested 307 chunks from ../medical_docs\\NGA-National_Guidelines_on_Self-Care_for_Sexual-Reproductive_and_Maternal_Health_2020.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ingested 452 chunks from ../medical_docs\\nigeria_national_guidelines_2016.pdf\n",
      "✓ Ingested 190 chunks from ../medical_docs\\PHCUOR-Implementation-Guidelines.pdf\n",
      "✓ Ingested 93 chunks from ../medical_docs\\PPP.pdf\n",
      "✓ Ingested 694 chunks from ../medical_docs\\SOP_and_MAP_Post_draft_print_and_indexed_new.pdf\n",
      "✓ Ingested 1574 chunks from ../medical_docs\\State of health in the African Region.pdf\n",
      "✓ Ingested 535 chunks from ../medical_docs\\Viral haemorrhagic fevers.pdf\n",
      "\n",
      "✅ Finished ingesting 13 documents (4825 chunks total)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4825"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    model='meta-llama/llama-4-scout-17b-16e-instruct',\n",
    "    api_key='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',\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "rag = MedicalRAGSystem(llm)\n",
    "\n",
    "rag.ingest_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a9459d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exists? False\n",
      "c:\\Users\\ELITEBOOK\\Documents\\Projects\\dca_hackathon\\ai_agent2\\modules\n"
     ]
    }
   ],
   "source": [
    "print(\"Folder exists?\", os.path.exists(\"medical_docs\"))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51138f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector store...\n",
      "Answer: **Treatment Protocol for Viral Infection**\n",
      "\n",
      "The treatment protocol for viral infections, particularly for severe cases, involves several key steps:\n",
      "\n",
      "1. **Supplemental Oxygen Therapy**: This is a hallmark of treatment for severe cases. Oxygen therapy should be commenced at 5L/min and titrated to reach a target SpO2 >90% (Source 2).\n",
      "2. **Empiric Therapy**: For severe cases, empiric therapy may include antiviral agents such as:\n",
      "\t* Remdesivir (a nucleotide-analog inhibitor of RNA-dependent RNA polymerases)\n",
      "\t* Lopinavir/ritonavir (LPV/RTV) - a protease inhibitor (Source 2).\n",
      "3. **De-escalation of Empiric Therapy**: Empiric therapy should be de-escalated based on microbiology results and clinical judgement (Source 2).\n",
      "\n",
      "**General Principles**\n",
      "\n",
      "* All areas where severely ill patients are being cared for should be equipped with pulse oximeter, functioning oxygen system, and disposable, single-use oxygen delivery interfaces (Source 2).\n",
      "\n",
      "**Discharge Protocol**\n",
      "\n",
      "When discharging a confirmed case that has completed treatment:\n",
      "\n",
      "* Patients should take a bath with soap and water before leaving the high-risk area.\n",
      "* They should wear fresh clothing and go home directly.\n",
      "* Clothing, shoes, and other materials should be disinfected with 0.5% chlorine solution or destroyed if heavily contaminated (Source 3).\n",
      "\n",
      "**Note**: These guidelines are general and may not apply to all viral infections. For specific guidance, consult a healthcare professional and refer to national guidelines or specific treatment protocols for the relevant viral infection.\n",
      "\n",
      "**Sources**:\n",
      "\n",
      "* Source 2: NATIONAL INTERIM GUIDELINES FOR CLINICAL MANAGEMENT OF COVID-19\n",
      "* Source 3: Guidelines for discharging a confirmed case that has completed treatment (no specific title provided)\n",
      "\n",
      "For clinical decisions, it is recommended to consult a healthcare professional.\n",
      "\n",
      "Sources:\n",
      "1. ../medical_docs\\Viral haemorrhagic fevers.pdf\n",
      "2. ../medical_docs\\177_1584210847.pdf\n",
      "3. ../medical_docs\\Viral haemorrhagic fevers.pdf\n",
      "4. ../medical_docs\\DSD-guidelines-Nigeria.pdf\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    from langchain_groq import ChatGroq\n",
    "    \n",
    "    llm = ChatGroq(\n",
    "        model='meta-llama/llama-4-scout-17b-16e-instruct',\n",
    "        api_key='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',\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    rag = MedicalRAGSystem(llm)\n",
    "    \n",
    "    # Setup knowledge base (first time only)\n",
    "    # setup_initial_knowledge_base(rag)\n",
    "    \n",
    "    # Query the system\n",
    "    result = rag.answer_with_sources(\n",
    "        \"What is the treatment protocol for viral infection?\"\n",
    "    )\n",
    "    \n",
    "    print(\"Answer:\", result['answer'])\n",
    "    print(\"\\nSources:\")\n",
    "    for i, source in enumerate(result['sources'], 1):\n",
    "        print(f\"{i}. {source['source']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c2978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
